{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "executionInfo": {
     "elapsed": 5973,
     "status": "ok",
     "timestamp": 1651066892290,
     "user": {
      "displayName": "einston eisnton",
      "userId": "06651033155891614631"
     },
     "user_tz": -480
    },
    "id": "5Phg7sDSKL7r",
    "outputId": "5efb318c-e0ec-44e1-ee3d-51fad9effb5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weicheng\\AppData\\Local\\Temp\\ipykernel_22052\\1940883857.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import resampy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model = tf.keras.models.load_model('babysound_classification_tf_cnn.h5')\n",
    "class_labels = [\"awake\",\"diaper\",\"hug\",\"hungry\",\"sleepy\",\"uncomfortable\"]\n",
    "predict_classes = class_labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judgelabel(labelname):\n",
    "  if labelname=='sleepy':\n",
    "    return 4\n",
    "  elif labelname=='hug':\n",
    "    return 2\n",
    "  elif labelname=='uncomfortable':\n",
    "    return 5\n",
    "  elif labelname=='diaper':\n",
    "    return 1\n",
    "  elif labelname=='awake':\n",
    "    return 0\n",
    "  elif labelname=='hungry':\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_pad_len = 174\n",
    "max_pad_len = 500\n",
    "num_rows = 40\n",
    "# num_columns = 174\n",
    "num_columns = 500   \n",
    "num_channels = 1\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", e)\n",
    "        # print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8LadHoN7XCqe"
   },
   "outputs": [],
   "source": [
    "def print_prediction_sta(file_name):\n",
    "    prediction_feature = extract_features(file_name) \n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "    predict_x=model.predict(prediction_feature) \n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "    predicted_class = le.inverse_transform(classes_x) \n",
    "    return class_labels[classes_x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1651067369263,
     "user": {
      "displayName": "einston eisnton",
      "userId": "06651033155891614631"
     },
     "user_tz": -480
    },
    "id": "Q6-1vY5t-P1Q",
    "outputId": "e14ebd78-3c51-4f0a-9515-49fe9a81c6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "diaper\n"
     ]
    }
   ],
   "source": [
    "filename = 'work/train/diaper/diaper_101_test.wav'\n",
    "print(print_prediction_sta(filename))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNJwCELSADpu8WhYW1ZO6TF",
   "collapsed_sections": [
    "EsyploZkDaKD",
    "ZmX8DZhrwU5n"
   ],
   "name": "babysound_classification_tf_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
